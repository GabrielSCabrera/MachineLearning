\section{Discussion}
    \subsection{Classification}
        % Logistic regression:
             % accuracy: bad/good?
             
        % Neural network
            % Choice of cost-function
            % Optimal weights and biases
            % best reg. params, learning rates
            % accuracy: bad/good?
        Figure \ref{fig:cc_acc} illustrates the success of the neural network algorithm developed for the study. The accuracy scores peak at an accuracy of nearly $72\%$ using the hyperparameter $\lambda = 10^{-4}$ and learning rate $\eta = 0.06$.
        
        Figure \ref{fig:cc_F1} illustrates the F1 scores for the grid search. These values are underwhelming as the F1 score is expected to be close to 1 for good model results. 
        
        It is also interesting that the hyperparameter and learning rate values which produce the best F1 scores do not match with the optimal $\lambda$ and $\eta$ values for the accuracy score.
        
        Figure \ref{fig:cc_auc}
        
        Figure \ref{fig:cc_gr}
        
        Figure \ref{fig:cc_F1}, \ref{fig:cc_auc} and \ref{fig:cc_gr} also shows that there's little  consistency between our evaluation methods, as each gives a different best value for $\eta$ and $\lambda$.
        
            
        % COMPARE the two methods: 
            % Give a critical discussion of the results obtained with LR and NN. 
            % Make an analysis of the regularization parameters and learning rates employed to find the optimal accuracy score.
            % Compare choice of cost-functions for the two: did we choose different ones?
        % Were the results from Yeh2009 reproduced? 
            % New remarks? 
            % Differences? 
            % Further analysis?
            
    \subsection{Regression}
        Ridge regression accomplished $MSE_{min}=0.2489$ at polynomial degree $p_{deg}=11$ and hyperparameter $\log\lambda=-9$.
        % Linear regression:
             % Choice of cost-function
             
        % Neural network
            % Choice of cost-function
            % Optimal weights and biases
            % best reg. params, learning rates
            
        % COMPARE the two methods: 
            % Give a critical discussion of the results obtained with LR and NN. 
            % Make an analysis of the regularization parameters and learning rates employed to find the optimal accuracy score.
            % Compare choice of cost-functions for the two: did we choose different ones?
     
    \subsection{Comparison of the Methods}
        % Summarize the various algorithms and include a critical evaluation of their pros and cons. Which algorithm is best for the regression and which is best for the classification.
        
        
        
        
        
        % May have been a good idea to add custom weight and bias initialization for each layer added? Would have solved the input mess.
        % There are several factors of the study which could have been performed better; some of which include data preprocessing, grid search rather than ..., and stochasticity between epochs.
        % F1 score is 'ill defined' if the network declares all values to be zeros
        % Should have maybe implemented MPI4PY (code parallelization), and
        % Should have maybe performed some cross validation to find the optimal parameters. This would however have been very computationally inefficient.